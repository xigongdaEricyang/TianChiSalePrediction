{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import mnist_inference\n",
    "import Layer2Model\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateDataSet(filePath, fileName):\n",
    "    #import and shuffle the data\n",
    "    df = pd.read_csv(os.path.join(filePath,fileName)).sample(frac=1).reset_index(drop=True)\n",
    "    normalizeColumns = ['compartment','TR','displacement','price_level','power','level_id',\n",
    "                    'cylinder_number','engine_torque','car_length','car_height','car_width','total_quality','equipment_quality',\n",
    "                    'rated_passenger','wheelbase','front_track','rear_track']\n",
    "    \n",
    "    leftDf = df.drop(normalizeColumns + ['sale_quantity'], axis =1)\n",
    "\n",
    "    normalizeDf = df[normalizeColumns]\n",
    "    normalizeDf = (normalizeDf-normalizeDf.min())/(normalizeDf.max()-normalizeDf.min())\n",
    "    inputDf = pd.concat([leftDf, normalizeDf], axis = 1)\n",
    "    inputX = inputDf.values\n",
    "    resultArray = df['sale_quantity'].values\n",
    "    inputY = resultArray.reshape((len(resultArray),1))\n",
    "#     trainX, testX, trainY, testY = \n",
    "    return train_test_split(inputX, inputY, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildGraph(model, dataSize):\n",
    "    INPUT_NODE = 245\n",
    "    OUTPUT_NODE = 1\n",
    "    BATCH_SIZE = 100\n",
    "    REGULARIZATION_RATE = 0.0001\n",
    "    LEARNING_RATE_BASE = 0.8\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.Graph().as_default():\n",
    "            x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x-input')\n",
    "            y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input')\n",
    "        \n",
    "            regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "            y = model.inference(x, regularizer)\n",
    "            global_step = tf.Variable(0, trainable=False)\n",
    "            \n",
    "            #add moving average\n",
    "            variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "            variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "            \n",
    "            #define Loss function\n",
    "            loss = tf.sqrt(tf.reduce_mean(tf.pow(tf.subtract(y, y_), 2)))\n",
    "            \n",
    "            learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE,global_step, dataSize / BATCH_SIZE, LEARNING_RATE_DECAY,staircase=True)\n",
    "            train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "            \n",
    "            with tf.control_dependencies([train_step, variables_averages_op]):\n",
    "                train_op = tf.no_op(name='train')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
